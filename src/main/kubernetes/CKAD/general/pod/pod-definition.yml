apiVersion: v1 # apps/v1
kind: Pod # pod, seervice , replica set, depolyment
metadata:
  name: mayapps-pod #name of the pod
  labels: #lables are consumed by selectors
    app: myapp
    type: front-end
    costcenter: amer
  annotations: #annotatons are only for information purpose
    buildVersion: 1.0
    devepoer: Dimuthu Senanayaka
spec:
  serviceAcccountName: dashboard-sa #this will auto bring the token as a volume (and now the default service account will not be mounted)
  #automountServiceAccountToken: choose not to mount default service account
  securityContext: #security context at spec level is applied to all the containers in the POD. what the POD or container can do on the host VM
    runAsUser: 1000
    capabilities:
      add: ["MAC_ADMIN"]  #add capabilities to the user. Only posisble at container level. Not at POD level.
  tolerations: #all values has to be within double quots
    - key: "app"
      operator: "Equal"
      value: "blue"
      effect: "NoExecute" #once this pod is deployed what should happen to the existing pods in node who does not have tolereation
  nodeName: foo-node #simple
  nodeSelector: #simple
    size: Large  #matches any of the labels (size or owner)
    owner: dimu
  nodeAffinity: #matches to the labels on the node. complex req
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        matchExpressions:
          - key: size
            operator: In
            values:
              - Large
              - Medium
            #- key: size
            #operator: NotIn
            #values:
            #  - Small
            #- key: size
            #operator: Exists #check only if label exists
  containers:
    - name: nginx-container
      securityContxt: #security context at container level override the security context coming from pod
        runAsUser: 1000
        capabilities:
          add: ["MAC_ADMIN"]
      image: nginx
      livenessProbe: # kube test the liveness and restart the pod if app is not live. for app which already in Ready state.
      # if the container inside the pod is killed -> then container get restart and traffic does not come to container until container is ready
      # livenessProbe can kill the app before it starts up if configured wrongly (Ex: )
      # ex : container may be stuck or malfunctionaing --> then liveness prob should fail
        hettpGet:
          path: /api/info
          port: 8080
        initialDelaySeconds: 10 #wait 10 sec before the first once the container is started
        periodSeconds : 5 #check liveness every 5 sec
        failureThreshold: 5 #after 5 times pod is not considered live
        successThreshold: 5 #after how many success evnets -> should be pod be considred live
      # tcpSocket:
      #   port: 3306
      # exec:
      #   command:
      #     - cat
      #     - /app/is_Ready
      readinessProbs: #called not only at the startup. this is used to know if the app is fine to serve traffic.
      # to decide it is good to route traffic (Running State). if readinessProb is failing then container is restarted
        httpGet:
          path: /api/actuator # container will not become Ready until this test is success
          port: 8080
        initialDelaySeconds: 10
        periodSeconds : 5
        failureThreshold: 5  # default is 3. after failureThreshould the pod will not be considred ready
      # tcpSocket:
      #   port: 3306
      # exec:
      #   command:
      #     - cat
      #     - /app/is_Ready
      startUpProbs: # when this is configured -> both rediness and liveness probs are not becomming active until startUp prob is ready. (this is since the start up of the app can take a long time which is not considred by liveness and readiness probs)
      command: ["sleep2"] #mapps to entrypoint of docker. and override the exising entrypoint defined with the docker image. This ignores both entry point and CMD provided in docker file and only cun command given here.
     #command: ['expr', '3', '+', '2'] #container just do this operation and die. container gets again and again created until the threshold. to avoid these restarts we can set podLevel property restartPolicy: Never (default is always)
      #command:
        #- "sleep"
        #- "1200"
      agrs: ["10"]  #will be passed to docker as startup defult argumnets CMD. (to the command available with in the docker image itself)
      envFrom:
        - configMapRef: #no need to mount the configMap
            name: app-config #set app-config as env variables in the container
        - secretRef:
            name: app-secrets #read secret file and set as env variables
      resources: #at container level
        requests:  #requirment to start the pod
          cpu: 1  # possible 0.1, 100m(m stands ofr milli), minimum is 1m. (cpu=1 => means 1 vcpu aws).  (docker world does not have a limit for resuce usage)
          memory: "1Gi" #256Mi, 1G(1000MB), 1Gi(1024MB)
        limit:
          cpu: 2 #kub throtal CPU usage at 2
          memory: "2Gi"  #kub DOES Not throtal memory. but if the container use exceeling limit of memory -> kub kills the container
      env:
        - name: APP_COLOR_ENV #environmnet variabls
          value: pink
        - name: APP_COLOR_CONFMAP
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: APP_COLOR
        - name: APP_COLOR_SECRET_REF
          valueFrom:
            secretKeyRef:
              name: app-secrets
              value: db-password
      volumeMounts:
        - mountPath: /opt
          name: data-volume-on-node
        - mountPath: /apps
          name: pvc-volume
  volumes:   # each value in the config/secret is created as a file in the pod /opt directory. at spec level of the pod
    - name: pvc-volume
      persistentVOlumeClaim:
        claimName: myClaim
    - name: sahred-data-volume  #this is a common data store shared between nodes
    - name: data-volume-on-node  #expose a directory in the host to be used as a volume in container
      hostPath:  #directory on host
        path: /data
        type: Directory
    - name: sahred-data-volume  #this is a common data store shared between nodes
      awsElasticBlockStore:
        volumeID: <vol-id>
        fsType: ext4
    - name: app-conf-volume
      configMap:
        name: app-config
    - name: app-secret-volume
      secret:
        secretName: app-secret

#kubectl create -f pod-definition.yml